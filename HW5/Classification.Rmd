---
title: "SVM Classification - Neo Zhao & Andrew Sen - CS4375"
output:
  pdf_document: default
---

## Linear Models

```{r}
library(tidyverse)
library(dplyr)
library(ROCR)
library(mccr)
library(ISLR)
library(caret)
library(tree)
library(rpart)
library(e1071)

# Source: https://www.kaggle.com/datasets/budnyak/wine-rating-and-price?select=Red.csv 

# Red, White, Rose, and Sparkling wine are all from the same dataset; however, separated by type

# Red Total: 8666 
Red <- read.csv("data/Red.csv")

# White Total: 3764
White <- read.csv("data/White.csv")

# Rose Total: 397
Rose <- read.csv("data/Rose.csv")

# Sparkling Total: 1007
Sparkling <- read.csv("data/Sparkling.csv")

# Combine the datasets together, Total: 13058
totalWine <- rbind(data = Red, data = White, data = Rose, data = Sparkling)

# Rename Ã¯..Name to just Name
names(totalWine)[1] <- "Name"

# Omit Names, Winery, & Region Column
totalWine <- subset(totalWine, select = -c(Name, Winery, Region))

# Omit all records where Year = N.V.
totalWine <- subset(totalWine, totalWine$Year != "N.V.")

# Omit all records where Rating = 3, Total: 12398
totalWine <- subset(totalWine, totalWine$Rating != 3)

# Omit all records before 2000s
totalWine <- subset(totalWine, totalWine$Year >= 2000)

# Make the Year from chr -> num
totalWine$Year <- as.numeric(totalWine$Year)

# Set Country from chr -> factor
totalWine$Country <- as.factor(totalWine$Country)

# Setting Ratings on a scale of 1 to 10
totalWine$Rating <- round(totalWine$Rating / 0.5) * 0.5
  
totalWine$Rating[totalWine$Rating == 0.5] <- 1
totalWine$Rating[totalWine$Rating == 1] <- 2
totalWine$Rating[totalWine$Rating == 1.5] <- 3
totalWine$Rating[totalWine$Rating == 2] <- 4
totalWine$Rating[totalWine$Rating == 2.5] <- 5
totalWine$Rating[totalWine$Rating == 3] <- 6
totalWine$Rating[totalWine$Rating == 3.5] <- 7
totalWine$Rating[totalWine$Rating == 4] <- 8
totalWine$Rating[totalWine$Rating == 4.5] <- 9
totalWine$Rating[totalWine$Rating == 5] <- 10

# Reorder Columns
totalWine <- totalWine[,c(1,2,3,5,4)]
```

```{r}
# Split to 80/20 Train/Test
set.seed(512)
i <- sample(1 : nrow(totalWine), nrow(totalWine) * 0.75, replace = FALSE)
train <- totalWine[i,]
test <- totalWine[-i,]

# Reducing size to 500
i <- sample(nrow(train), size = 500, replace = FALSE)
train_sample <- train[i,]
```

### Data Exploration
```{r}
# 1) summary()
summary(train)
```

```{r}
# 2) is.na()
colSums(is.na(train))
colSums(is.na(test))
```

```{r}
# 3) str()
str(train)
```

```{r}
# 4) head() functions
head(train)
```

```{r}
# 5) cor() and pairs()
cor(train[,c(-1, -4)])

pairs(train[,c(-1, -4)])
```

### Informative Graphs
```{r}
# Red
plot(Rating ~ Price, data = Red, main = "Red Wine", xlab = "Price", ylab = "Rating")

# White
plot(Rating ~ Price, data = White, main = "White Wine", xlab = "Price", ylab = "Rating")

# Rose
plot(Rating ~ Price, data = Rose, main = "Rose Wine", xlab = "Price", ylab = "Rating")

# Sparkling
plot(Rating ~ Price, data = Sparkling, main = "Sparkling Wine", xlab = "Price", ylab = "Rating")
```

### SVM Regression - Linear 
```{r}
svm1 <- tune.svm(Rating ~., data = train_sample, kernel = "linear",
 cost=c(0.001, 0.01, 0.1, 1, 5, 10, 100)
)$best.model

summary(svm1)
```

```{r}
# Evaluate
pred <- predict(svm1, newdata = test)
head(table(pred, test$Rating))
cor_svm1 <- cor(pred, test$Rating)
mse_svm1 <- mean((pred - test$Rating)^2)
print(paste('Correlation: ', cor_svm1))
print(paste('MSE: ', mse_svm1))
```


### Polynomial
```{r}
svm2 <- tune.svm(Rating ~ ., data = train_sample, kernel = "polynomial",
 cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)
)$best.model

summary(svm2)
```

```{r}
# Evaluate
pred <- predict(svm2, newdata = test)
head(table(pred, test$Rating))
cor_svm2 <- cor(pred, test$Rating)
mse_svm2 <- mean((pred - test$Rating)^2)
print(paste('Correlation: ', cor_svm2))
print(paste('MSE: ', mse_svm2))
```

### Radial Kernel
```{r}
svm3 <- tune.svm(Rating ~ ., data = train_sample, kernel = "radial",
 cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100), gamma = c(0.001, 0.01, 0.1, 1, 5, 10, 100)
)$best.model

summary(svm3)
```

```{r}
# Evaluate
pred <- predict(svm3, newdata = test)
head(table(pred, test$Rating))
cor_svm3 <- cor(pred, test$Rating)
mse_svm3 <- mean((pred - test$Rating)^2)
print(paste('Correlation: ', cor_svm3))
print(paste('MSE: ', mse_svm3))
```

### Conclusion

* Linear Kernel has the most middle performance out of all three; however, it's probably still not the best  fit for this dataset as the correlation is still quite low. Therefore, Linear Kernel probably isn't any better than Simple Linear Regression, and we would get a similar Correlation value. 
* Polynomial Kernel has poor performance out of the three. It's possible that the model has overfitted due to tuning. 
* Radial Kernel has the best performance as it is the most generalized form of kernelization. 